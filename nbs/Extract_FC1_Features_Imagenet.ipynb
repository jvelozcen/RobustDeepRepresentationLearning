{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports utils data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils_data_exploration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imported dataframes\n",
    "df_train_labels\n",
    "df_test_photo_to_biz_ids\n",
    "photos_in_test_biz; # dictionary that maps a test buisness with photos ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>photos</th>\n",
       "      <th>n_photo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7)</td>\n",
       "      <td>[438623, 325966, 227692, 407856, 368729, 16319...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>(0, 1, 6, 8)</td>\n",
       "      <td>[298536, 20346, 8457, 308694, 349310, 407838, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>[338465, 328433, 243861, 361777, 127198, 46652...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "      <td>[46472, 341947, 396253, 75316, 42330, 244095, ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>(0, 6, 8)</td>\n",
       "      <td>[118251, 219940, 27517, 8578, 148347, 433559, ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            labels  \\\n",
       "business_id                          \n",
       "1000         (1, 2, 3, 4, 5, 6, 7)   \n",
       "1001                  (0, 1, 6, 8)   \n",
       "100             (1, 2, 4, 5, 6, 7)   \n",
       "1006               (1, 2, 4, 5, 6)   \n",
       "1010                     (0, 6, 8)   \n",
       "\n",
       "                                                        photos  n_photo  \n",
       "business_id                                                              \n",
       "1000         [438623, 325966, 227692, 407856, 368729, 16319...       54  \n",
       "1001         [298536, 20346, 8457, 308694, 349310, 407838, ...        9  \n",
       "100          [338465, 328433, 243861, 361777, 127198, 46652...       84  \n",
       "1006         [46472, 341947, 396253, 75316, 42330, 244095, ...       22  \n",
       "1010         [118251, 219940, 27517, 8578, 148347, 433559, ...       11  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317818</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30679</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455084</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371381</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86224</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   photo_id business_id\n",
       "0    317818       003sg\n",
       "1     30679       003sg\n",
       "2    455084       003sg\n",
       "3    371381       003sg\n",
       "4     86224       003sg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_photo_to_biz_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237152"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_photo_to_biz_ids['photo_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266268</th>\n",
       "      <td>3</td>\n",
       "      <td>7sa4h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943234</th>\n",
       "      <td>3</td>\n",
       "      <td>sip1t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153375</th>\n",
       "      <td>3</td>\n",
       "      <td>z0xdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180870</th>\n",
       "      <td>3</td>\n",
       "      <td>zo14i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         photo_id business_id\n",
       "266268          3       7sa4h\n",
       "943234          3       sip1t\n",
       "1153375         3       z0xdo\n",
       "1180870         3       zo14i"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_photo_to_biz_ids[df_test_photo_to_biz_ids['photo_id'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Assign Directory Paths to Constant Variable Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/javier/Documents/YelpRestaurantPhotoClassification/nbs'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd # verify you are in the correct folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LESSON_HOME_DIR = os.getcwd()\n",
    "DATA_DIR = LESSON_HOME_DIR + '/../data/'\n",
    "TRAIN_PATH = DATA_DIR + '/train_photos/'\n",
    "TEST_PATH = DATA_DIR + '/test_photos/'\n",
    "VALID_PATH = DATA_DIR + '/valid_photos/'\n",
    "RESULTS_PATH = DATA_DIR + '/results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Map Train Photos to FC1 Representation Using VGG16-Imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For every training image subtract the per channel mean of the imagenet dataset\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1, 1, 3))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "        \n",
    "        Args:\n",
    "            x: Image array (height x width x channels)\n",
    "        \n",
    "        Returns\n",
    "               Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(preprocessing_function=vgg_preprocess) # No data augmentation is being applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237152 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = gen.flow_from_directory(TEST_PATH, target_size=(224, 224), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the VGG16 model with it's pre trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave just the first fully connected layer to calculate the new representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_extract_features = Model(inputs=model.layers[0].input, outputs=model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 117,479,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_extract_features.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract bottleneck features for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2960/2960 [==============================] - 14246s \n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train = model_extract_features.predict_generator(batches, batches.n // batches.batch_size + 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + 'bottleneck_features_train.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_features_train = np.load(RESULTS_PATH + 'bottleneck_features_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234842, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract bottleneck features for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706/3706 [==============================] - 12753s \n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_test = model_extract_features.predict_generator(batches, batches.n // batches.batch_size + 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + '/imagenet/features/' + 'bottleneck_features_test.npy', bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237152, 4096)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve image filenames associated with the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the filenames for the entire training set\n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(filenames, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237152"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + '/imagenet/' + 'test_filenames.npy', filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.load(RESULTS_PATH + '/imagenet/' + 'test### Retrieve image filenames associated with the training features\n",
    "\n",
    "# get the filenames for the entire training set\n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]\n",
    "\n",
    "filenames = np.array(filenames, dtype=np.int32)\n",
    "\n",
    "np.save(RESULTS_PATH + 'train_filenames.npy', train_filenames)\n",
    "\n",
    "filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames.shape_filenames.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237152,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filenames = np.load(RESULTS_PATH + 'train_filenames.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_filenames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve image filenames associated with the training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the filenames for the entire training set\n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filenames = np.array(filenames, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + 'test_filenames.npy', train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.load(RESULTS_PATH + 'train_filenames.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filenames = np.load(RESULTS_PATH + 'train_filenames.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234842,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Obtain each restaurant fc1 blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the restaurants training data; Important so that we don't have to shuffle later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>photos</th>\n",
       "      <th>n_photo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7)</td>\n",
       "      <td>[438623, 325966, 227692, 407856, 368729, 16319...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>(0, 1, 6, 8)</td>\n",
       "      <td>[298536, 20346, 8457, 308694, 349310, 407838, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>[338465, 328433, 243861, 361777, 127198, 46652...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "      <td>[46472, 341947, 396253, 75316, 42330, 244095, ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>(0, 6, 8)</td>\n",
       "      <td>[118251, 219940, 27517, 8578, 148347, 433559, ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            labels  \\\n",
       "business_id                          \n",
       "1000         (1, 2, 3, 4, 5, 6, 7)   \n",
       "1001                  (0, 1, 6, 8)   \n",
       "100             (1, 2, 4, 5, 6, 7)   \n",
       "1006               (1, 2, 4, 5, 6)   \n",
       "1010                     (0, 6, 8)   \n",
       "\n",
       "                                                        photos  n_photo  \n",
       "business_id                                                              \n",
       "1000         [438623, 325966, 227692, 407856, 368729, 16319...       54  \n",
       "1001         [298536, 20346, 8457, 308694, 349310, 407838, ...        9  \n",
       "100          [338465, 328433, 243861, 361777, 127198, 46652...       84  \n",
       "1006         [46472, 341947, 396253, 75316, 42330, 244095, ...       22  \n",
       "1010         [118251, 219940, 27517, 8578, 148347, 433559, ...       11  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_business = df_train_labels.index.get_values()\n",
    "unique_business = np.sort(unique_business) # returns a copy of the sorted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   4,   5,   6,   7,   8,   9,  12,  13,  14,  16,  18,  19,\n",
       "        21,  23,  24,  26,  28,  29,  32,  35,  36,  37,  38,  39,  41,\n",
       "        48,  50,  51,  54,  58,  60,  63,  65,  67,  68,  69,  71,  74,\n",
       "        75,  77,  78,  79,  81,  84,  85,  87,  89,  91,  93,  96,  99,\n",
       "       100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 115, 118, 119,\n",
       "       120, 123, 125, 129, 131, 132, 135, 140, 142, 143, 145, 147, 148,\n",
       "       150, 153, 154, 157, 158, 161, 162, 163, 164, 165, 169, 171, 172,\n",
       "       175, 177, 179, 180, 183, 184, 186, 187, 188])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "np.random.shuffle(unique_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2469, 2480,  722,  955,  319,  876, 2265, 1386, 2369, 2305, 1260,\n",
       "       3077,  131, 1229,  966, 2213, 2108,  298, 3521, 2801, 3013, 3301,\n",
       "        163, 1419, 1856,  908, 2166, 2391, 2935, 1903, 2020, 2640, 1065,\n",
       "          6, 2796, 3074, 3905, 2234, 1783, 2401, 3168, 3877,  157,  494,\n",
       "       2500, 2285, 1656, 1413, 2817,  501,   60, 3218, 1026, 1055, 2357,\n",
       "        916, 3211, 3762, 3798, 3149, 1101, 1661, 3874,  495, 2434,  906,\n",
       "       2023, 1537, 3693,  112, 2955, 1760, 3849,  161, 2748, 2134,  846,\n",
       "       2540, 2671, 1993, 3430, 3170,  109, 3827,  806, 1490, 1626,  626,\n",
       "        276, 2018, 1503, 1647, 3226, 1533, 2296, 1142, 3497, 3570, 2810,\n",
       "       2494])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the shuffled businesses\n",
    "np.save(RESULTS_PATH+'/businesses_shuffled.npy', unique_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the first fc layer representation for every restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = []\n",
    "features_shape = (1, bottleneck_features_train.shape[1])\n",
    "\n",
    "for i, business in enumerate(unique_business):\n",
    "    business_photos = df_train_labels.loc[business].photos\n",
    "    restaurant_fc1_features.append(np.zeros(features_shape))\n",
    "    photo_count = 0\n",
    "    for business_photo in business_photos:\n",
    "        restaurant_fc1_features[i] += bottleneck_features_train[np.where(train_filenames == business_photo)[0]]\n",
    "        photo_count += 1\n",
    "    restaurant_fc1_features[i] = restaurant_fc1_features[i] / photo_count\n",
    "\n",
    "restaurant_fc1_features = np.array(restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = restaurant_fc1_features.reshape(1996, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 4096)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_fc1_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Retrieve image filenames associated with the training features\n",
    "\n",
    "# get the filenames for the entire training set\n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]\n",
    "\n",
    "filenames = np.array(filenames, dtype=np.int32)\n",
    "\n",
    "np.save(RESULTS_PATH + 'train_filenames.npy', train_filenames)\n",
    "\n",
    "filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames.shape### Retrieve image filenames associated with the training features\n",
    "\n",
    "# get the filenames for the entire training set\n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]\n",
    "\n",
    "filenames = np.array(filenames, dtype=np.int32)\n",
    "\n",
    "np.save(RESULTS_PATH + 'train_filenames.npy', train_filenames)\n",
    "\n",
    "filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames.shape### Retrieve image filenames associated with the training features\n",
    "\n",
    "# get the filenames for the entire training set\n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]\n",
    "\n",
    "filenames = np.array(filenames, dtype=np.int32)\n",
    "\n",
    "np.save(RESULTS_PATH + 'train_filenames.npy', train_filenames)\n",
    "\n",
    "filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames = np.load(RESULTS_PATH + 'train_filenames.npy')\n",
    "\n",
    "train_filenames.shape# save the fc1 blueprint corresponding to each of the unique businesses\n",
    "np.save(RESULTS_PATH+'/businesses_fc1_blueprint.npy', restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this notebook ends here, Gratz!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Obtain each test restaurant fc1 blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the restaurants training data; Important so that we don't have to shuffle later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_business = df_test_photo_to_biz_ids['business_id'].unique()\n",
    "unique_business = np.sort(unique_business) # returns a copy of the sorted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['003sg', '00er5', '00kad', '00mc6', '00q7x', '00v0t', '00y7p',\n",
       "       '019fg', '019r1', '01i5j', '01is9', '01mrb', '01pyb', '01s0p',\n",
       "       '01xsq', '021oz', '026nc', '02bwy', '02d9t', '02eos', '02fio',\n",
       "       '02pxt', '02qrp', '02rfd', '0357u', '035x6', '038l4', '03bbu',\n",
       "       '03ked', '03m8y', '03vx8', '03yz9', '040nh', '042hy', '044sl',\n",
       "       '045qe', '04944', '04cy7', '04ilw', '04imx', '04kgm', '04ud9',\n",
       "       '04wn2', '04zgs', '050l6', '0573e', '057qc', '05fb2', '05h9r',\n",
       "       '05ihx', '05jhx', '05rwc', '06cko', '06fzh', '06gbm', '06ml0',\n",
       "       '06p0g', '06ums', '06vhp', '0707d', '070ll', '077lb', '07bbs',\n",
       "       '07gmf', '07nri', '07o52', '084gg', '084v2', '08dzw', '08h8f',\n",
       "       '08ni5', '08oeq', '08wfz', '0916a', '092lt', '098ef', '098un',\n",
       "       '09ckq', '09ejq', '09iat', '09kll', '09pmi', '09ptq', '09w5k',\n",
       "       '0a1ko', '0a45c', '0a938', '0adc9', '0adst', '0ahhr', '0aj6u',\n",
       "       '0akmq', '0au0t', '0axc7', '0axvc', '0b8ky', '0bcfg', '0beyy',\n",
       "       '0bnm5', '0bzjp'], dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "np.random.shuffle(unique_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['l3hce', 'nim76', '57z69', 'bvw6i', '0rzi7', '4dnpo', '6v6r4',\n",
       "       'yqld5', 'ub57s', 'r26ek', '9bfqp', '3k8b1', 'gsqc0', 'dikt8',\n",
       "       'ebyno', 'exqyg', 'x75wv', 'wcln6', 'gn80r', 'vd75i', 'scc07',\n",
       "       'd74of', '9kj6g', 'pjxce', '8oui7', 'k8s6m', '321ey', '39gcr',\n",
       "       'mnc6a', '8uhqa', 'a58kk', 'ouoo1', 'qbm0k', 'sjjdd', 'jd9ky',\n",
       "       '0nq6o', 'uotly', 'rwgnf', 'oab77', 'i95mo', 'lesy6', 'y3zpu',\n",
       "       'pfhqw', 'nzy2m', '6ssbi', '1zjuy', 'mm6dj', '7y7gr', 'e9n68',\n",
       "       '3o0k1', 'pqdoa', 'chici', 'fgbk6', 'bvb54', 'eok7m', 'n3eg2',\n",
       "       'a0llc', 'x9iey', 'fup0v', 'hwxzm', '7l3qq', 's1ysp', '4w5dg',\n",
       "       'j0sy8', '0tc9p', 'u30yi', 'aj2c4', '9gy9k', '3j75n', 'jza3m',\n",
       "       'poe4x', '9xo1p', 'nrm98', 'vbthe', 'kkl9u', '0s3z5', '3yz1o',\n",
       "       'zq5am', 'g07ov', 'p1l60', 'jubx3', 'gv3y7', '3i7w0', 'sf6dy',\n",
       "       'cgvtr', 'qzqhw', 'hw3ht', 'j2z1w', '19c32', '7rjw4', 'zcd1t',\n",
       "       'qhcbe', 'khriv', 'bfmq5', '4y0gz', 'q102l', '7f24o', 'datj5',\n",
       "       'fz0aw', '5ukiq'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the shuffled businesses\n",
    "np.save(DATA_DIR + '/shared/' +'/test_businesses_shuffled.npy', unique_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the first fc layer representation for every restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = []\n",
    "features_shape = (1, bottleneck_features_test.shape[1])\n",
    "\n",
    "for i, business in enumerate(unique_business):\n",
    "    business_photos = df_test_photo_to_biz_ids[df_test_photo_to_biz_ids['business_id'] == business]['photo_id'].as_matrix()\n",
    "    restaurant_fc1_features.append(np.zeros(features_shape))\n",
    "    photo_count = 0\n",
    "    for business_photo in business_photos:\n",
    "        restaurant_fc1_features[i] += bottleneck_features_test[np.where(filenames == business_photo)[0]]\n",
    "        photo_count += 1\n",
    "    restaurant_fc1_features[i] = restaurant_fc1_features[i] / photo_count\n",
    "\n",
    "restaurant_fc1_features = np.array(restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = restaurant_fc1_features.reshape(10000, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4096)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_fc1_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.17446654,  1.15032917,  1.09108251, ...,  2.38044859,\n",
       "         1.53568873,  0.20470579],\n",
       "       [ 1.80752024,  2.02153297,  1.3848336 , ...,  1.95438128,\n",
       "         1.26758549,  0.13444891],\n",
       "       [ 1.57852717,  1.75416363,  2.30216543, ...,  3.03419325,\n",
       "         1.01502079,  0.44100595],\n",
       "       ..., \n",
       "       [ 1.70478558,  2.36583228,  1.22405197, ...,  1.05381226,\n",
       "         0.85718813,  0.16915629],\n",
       "       [ 2.3860694 ,  0.77662372,  1.49644853, ...,  2.43986367,\n",
       "         1.18885089,  0.25047417],\n",
       "       [ 1.89444393,  2.10856588,  1.87857879, ...,  1.63456469,\n",
       "         1.20462462,  0.56510732]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_fc1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Retrieve image filenames associated with the training features\n",
    "np.save(RESULTS_PATH+ '/imagenet/' +'/test_businesses_fc1_blueprint.npy', restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
