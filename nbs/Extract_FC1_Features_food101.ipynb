{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract FC1 Features Food 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import gc\n",
    "from utils_data_exploration import * # import all datastructures and functions from utils data exploration\n",
    "\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Imported dataframes\n",
    "df_train_labels\n",
    "df_test_photo_to_biz_ids\n",
    "photos_in_test_biz; # dictionary that maps a test buisness with photos ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Assign Directory Paths to Constant Variable Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'food101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LESSON_HOME_DIR = os.getcwd()\n",
    "DATA_DIR = LESSON_HOME_DIR + '/../data/'\n",
    "TRAIN_PATH = DATA_DIR + '/train_photos/'\n",
    "TEST_PATH = DATA_DIR + '/test_photos/'\n",
    "VALID_PATH = DATA_DIR + '/valid_photos/'\n",
    "\n",
    "# representation specific paths\n",
    "RESULTS_PATH = DATA_DIR + '/results/' + '/' + dataset + '/'\n",
    "WEIGHTS_PATH = DATA_DIR + '/weights/' + '/' + dataset + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Train Photos to FC1 Representation Using VGG16 - Food 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the VGG16 model with its pre-trained Food-101 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json, load_model, Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model weight and structure\n",
    "model = load_model(WEIGHTS_PATH+'vgg16_food101_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javier/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fc...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# Keep the feature extraction section\n",
    "model_extract_features = Model(input=model.layers[0].input, output=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Instantiate Image Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For every training image subtract the per channel mean of the imagenet dataset\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((1, 1, 3))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "        \n",
    "        Args:\n",
    "            x: Image array (height x width x channels)\n",
    "        \n",
    "        Returns\n",
    "               Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(preprocessing_function=vgg_preprocess) # No data augmentation is being applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract bottleneck features for the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 237152 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = gen.flow_from_directory(TRAIN_PATH, target_size=(224, 224), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706/3706 [==============================] - 3509s  \n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train = model_extract_features.predict_generator(batches, batches.n // batches.batch_size + 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234842, 4096)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + 'bottleneck_features_train.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_features_train = np.load(RESULTS_PATH + 'bottleneck_features_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = gen.flow_from_directory(TEST_PATH, target_size=(224, 224), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3706/3706 [==============================] - 3509s  \n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_test = model_extract_features.predict_generator(batches, batches.n // batches.batch_size + 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237152, 4096)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + 'bottleneck_features_test.npy', bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237152, 4096)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_features_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve image filenames associated with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the filenames for the entire trained \n",
    "filenames = batches.filenames\n",
    "filenames = [f.split('/')[1] for f in filenames]\n",
    "filenames = [f.split('.')[0] for f in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = np.array(filenames, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237152,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/javier/Documents/YelpRestaurantPhotoClassification/nbs/../data//results//food101/'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type_str = 'test' # select if using train or test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(RESULTS_PATH + type_str +'_filenames.npy', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain each restaurant fc1 blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the restaurants training data; Important so that we don't have to shuffle later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>photos</th>\n",
       "      <th>n_photo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7)</td>\n",
       "      <td>[438623, 325966, 227692, 407856, 368729, 16319...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>(0, 1, 6, 8)</td>\n",
       "      <td>[298536, 20346, 8457, 308694, 349310, 407838, ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>(1, 2, 4, 5, 6, 7)</td>\n",
       "      <td>[338465, 328433, 243861, 361777, 127198, 46652...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>(1, 2, 4, 5, 6)</td>\n",
       "      <td>[46472, 341947, 396253, 75316, 42330, 244095, ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>(0, 6, 8)</td>\n",
       "      <td>[118251, 219940, 27517, 8578, 148347, 433559, ...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            labels  \\\n",
       "business_id                          \n",
       "1000         (1, 2, 3, 4, 5, 6, 7)   \n",
       "1001                  (0, 1, 6, 8)   \n",
       "100             (1, 2, 4, 5, 6, 7)   \n",
       "1006               (1, 2, 4, 5, 6)   \n",
       "1010                     (0, 6, 8)   \n",
       "\n",
       "                                                        photos  n_photo  \n",
       "business_id                                                              \n",
       "1000         [438623, 325966, 227692, 407856, 368729, 16319...       54  \n",
       "1001         [298536, 20346, 8457, 308694, 349310, 407838, ...        9  \n",
       "100          [338465, 328433, 243861, 361777, 127198, 46652...       84  \n",
       "1006         [46472, 341947, 396253, 75316, 42330, 244095, ...       22  \n",
       "1010         [118251, 219940, 27517, 8578, 148347, 433559, ...       11  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_business = df_train_labels.index.get_values()\n",
    "unique_business = np.sort(unique_business) # returns a copy of the sorted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   4,   5,   6,   7,   8,   9,  12,  13,  14,  16,  18,  19,\n",
       "        21,  23,  24,  26,  28,  29,  32,  35,  36,  37,  38,  39,  41,\n",
       "        48,  50,  51,  54,  58,  60,  63,  65,  67,  68,  69,  71,  74,\n",
       "        75,  77,  78,  79,  81,  84,  85,  87,  89,  91,  93,  96,  99,\n",
       "       100, 101, 103, 104, 105, 108, 109, 110, 111, 112, 115, 118, 119,\n",
       "       120, 123, 125, 129, 131, 132, 135, 140, 142, 143, 145, 147, 148,\n",
       "       150, 153, 154, 157, 158, 161, 162, 163, 164, 165, 169, 171, 172,\n",
       "       175, 177, 179, 180, 183, 184, 186, 187, 188])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "np.random.shuffle(unique_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2469, 2480,  722,  955,  319,  876, 2265, 1386, 2369, 2305, 1260,\n",
       "       3077,  131, 1229,  966, 2213, 2108,  298, 3521, 2801, 3013, 3301,\n",
       "        163, 1419, 1856,  908, 2166, 2391, 2935, 1903, 2020, 2640, 1065,\n",
       "          6, 2796, 3074, 3905, 2234, 1783, 2401, 3168, 3877,  157,  494,\n",
       "       2500, 2285, 1656, 1413, 2817,  501,   60, 3218, 1026, 1055, 2357,\n",
       "        916, 3211, 3762, 3798, 3149, 1101, 1661, 3874,  495, 2434,  906,\n",
       "       2023, 1537, 3693,  112, 2955, 1760, 3849,  161, 2748, 2134,  846,\n",
       "       2540, 2671, 1993, 3430, 3170,  109, 3827,  806, 1490, 1626,  626,\n",
       "        276, 2018, 1503, 1647, 3226, 1533, 2296, 1142, 3497, 3570, 2810,\n",
       "       2494])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the shuffled businesses\n",
    "np.save(RESULTS_PATH+'/businesses_shuffled.npy', unique_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the first fc layer representation for every restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = []\n",
    "features_shape = (1, bottleneck_features_train.shape[1])\n",
    "\n",
    "for i, business in enumerate(unique_business):\n",
    "    business_photos = df_train_labels.loc[business].photos\n",
    "    restaurant_fc1_features.append(np.zeros(features_shape))\n",
    "    photo_count = 0\n",
    "    for business_photo in business_photos:\n",
    "        restaurant_fc1_features[i] += bottleneck_features_train[np.where(train_filenames == business_photo)[0]]\n",
    "        photo_count += 1\n",
    "    restaurant_fc1_features[i] = restaurant_fc1_features[i] / photo_count\n",
    "\n",
    "restaurant_fc1_features = np.array(restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = restaurant_fc1_features.reshape(1996, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1996, 4096)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_fc1_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the fc1 blueprint corresponding to each of the unique businesses\n",
    "np.save(RESULTS_PATH + '/features/' + 'businesses_fc1_blueprint', restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the restaurants training data; Important so that we don't have to shuffle later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_business = df_test_photo_to_biz_ids['business_id'].unique()\n",
    "unique_business = np.sort(unique_business) # returns a copy of the sorted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "np.random.shuffle(unique_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['l3hce', 'nim76', '57z69', 'bvw6i', '0rzi7', '4dnpo', '6v6r4',\n",
       "       'yqld5', 'ub57s', 'r26ek', '9bfqp', '3k8b1', 'gsqc0', 'dikt8',\n",
       "       'ebyno', 'exqyg', 'x75wv', 'wcln6', 'gn80r', 'vd75i', 'scc07',\n",
       "       'd74of', '9kj6g', 'pjxce', '8oui7', 'k8s6m', '321ey', '39gcr',\n",
       "       'mnc6a', '8uhqa', 'a58kk', 'ouoo1', 'qbm0k', 'sjjdd', 'jd9ky',\n",
       "       '0nq6o', 'uotly', 'rwgnf', 'oab77', 'i95mo', 'lesy6', 'y3zpu',\n",
       "       'pfhqw', 'nzy2m', '6ssbi', '1zjuy', 'mm6dj', '7y7gr', 'e9n68',\n",
       "       '3o0k1', 'pqdoa', 'chici', 'fgbk6', 'bvb54', 'eok7m', 'n3eg2',\n",
       "       'a0llc', 'x9iey', 'fup0v', 'hwxzm', '7l3qq', 's1ysp', '4w5dg',\n",
       "       'j0sy8', '0tc9p', 'u30yi', 'aj2c4', '9gy9k', '3j75n', 'jza3m',\n",
       "       'poe4x', '9xo1p', 'nrm98', 'vbthe', 'kkl9u', '0s3z5', '3yz1o',\n",
       "       'zq5am', 'g07ov', 'p1l60', 'jubx3', 'gv3y7', '3i7w0', 'sf6dy',\n",
       "       'cgvtr', 'qzqhw', 'hw3ht', 'j2z1w', '19c32', '7rjw4', 'zcd1t',\n",
       "       'qhcbe', 'khriv', 'bfmq5', '4y0gz', 'q102l', '7f24o', 'datj5',\n",
       "       'fz0aw', '5ukiq'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_business[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the shuffled businesses\n",
    "np.save(DATA_DIR + '/shared/' +'/test_businesses_shuffled.npy', unique_business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the first fc layer representation for every restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>317818</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30679</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>455084</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>371381</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86224</td>\n",
       "      <td>003sg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   photo_id business_id\n",
       "0    317818       003sg\n",
       "1     30679       003sg\n",
       "2    455084       003sg\n",
       "3    371381       003sg\n",
       "4     86224       003sg"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_photo_to_biz_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = []\n",
    "features_shape = (1, bottleneck_features_test.shape[1])\n",
    "\n",
    "for i, business in enumerate(unique_business):\n",
    "    business_photos = df_test_photo_to_biz_ids[df_test_photo_to_biz_ids['business_id'] == business]['photo_id'].as_matrix()\n",
    "    restaurant_fc1_features.append(np.zeros(features_shape))\n",
    "    photo_count = 0\n",
    "    for business_photo in business_photos:\n",
    "        restaurant_fc1_features[i] += bottleneck_features_test[np.where(filenames == business_photo)[0]]\n",
    "        photo_count += 1\n",
    "    restaurant_fc1_features[i] = restaurant_fc1_features[i] / photo_count\n",
    "\n",
    "restaurant_fc1_features = np.array(restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_fc1_features = restaurant_fc1_features.reshape(10000, 4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4096)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_fc1_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Retrieve image filenames associated with the training features\n",
    "np.save(RESULTS_PATH +'/test_businesses_fc1_blueprint.npy', restaurant_fc1_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this notebook ends here, Gratz!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
